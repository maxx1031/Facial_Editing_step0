#!/usr/bin/env python3
"""
Environment check script for FLUX Face Emotion Pipeline.
Verifies all dependencies and configurations are ready.
"""

import os
import sys
from pathlib import Path


def check_python_version():
    """Check Python version."""
    version = sys.version_info
    if version.major == 3 and version.minor >= 9:
        print(f"âœ… Python {version.major}.{version.minor}.{version.micro}")
        return True
    else:
        print(f"âŒ Python {version.major}.{version.minor}.{version.micro} (éœ€è¦ Python 3.9+)")
        return False


def check_cuda():
    """Check CUDA availability."""
    try:
        import torch
        if torch.cuda.is_available():
            cuda_version = torch.version.cuda
            device_count = torch.cuda.device_count()
            device_name = torch.cuda.get_device_name(0)
            print(f"âœ… CUDA {cuda_version} å¯ç”¨")
            print(f"   - {device_count} ä¸ª GPU è®¾å¤‡")
            print(f"   - ä¸»è®¾å¤‡: {device_name}")

            # æ˜¾ç¤ºæ‰€æœ‰ GPU
            for i in range(device_count):
                name = torch.cuda.get_device_name(i)
                props = torch.cuda.get_device_properties(i)
                total_mem_gb = props.total_memory / (1024**3)
                print(f"   - GPU {i}: {name} ({total_mem_gb:.1f} GB)")
            return True
        else:
            print("âŒ CUDA ä¸å¯ç”¨")
            return False
    except ImportError:
        print("âŒ PyTorch æœªå®‰è£…")
        return False


def check_package(package_name, import_name=None):
    """Check if a package is installed."""
    if import_name is None:
        import_name = package_name

    try:
        module = __import__(import_name)
        version = getattr(module, '__version__', 'unknown')
        print(f"âœ… {package_name}: {version}")
        return True
    except ImportError:
        print(f"âŒ {package_name}: æœªå®‰è£…")
        return False


def check_env_vars():
    """Check environment variables."""
    results = {}

    # OPENAI_API_KEY (optional for GPT mode)
    openai_key = os.environ.get("OPENAI_API_KEY")
    if openai_key:
        masked = openai_key[:7] + "..." + openai_key[-4:] if len(openai_key) > 11 else "***"
        print(f"âœ… OPENAI_API_KEY: {masked}")
        results['openai'] = True
    else:
        print("âš ï¸  OPENAI_API_KEY: æœªè®¾ç½® (ä½¿ç”¨ --backend gpt æ—¶éœ€è¦)")
        results['openai'] = False

    # HF_TOKEN (optional for FLUX.2-klein-9B)
    hf_token = os.environ.get("HF_TOKEN")
    if hf_token:
        masked = "hf_" + "..." + hf_token[-4:] if len(hf_token) > 7 else "***"
        print(f"âœ… HF_TOKEN: {masked}")
        results['hf'] = True
    else:
        print("âš ï¸  HF_TOKEN: æœªè®¾ç½® (ä½¿ç”¨ FLUX.2-klein-9B æ—¶éœ€è¦)")
        results['hf'] = False

    return results


def check_config():
    """Check if config.yaml exists and is valid."""
    config_path = Path("config.yaml")
    if not config_path.exists():
        print("âŒ config.yaml ä¸å­˜åœ¨")
        return False

    try:
        import yaml
        with open(config_path) as f:
            config = yaml.safe_load(f)

        # Check key sections
        required_sections = ['generation', 'scale', 'filtering', 'paths', 'emotions', 'emotion_pairs']
        missing = [s for s in required_sections if s not in config]

        if missing:
            print(f"âŒ config.yaml ç¼ºå°‘éƒ¨åˆ†: {', '.join(missing)}")
            return False

        print(f"âœ… config.yaml æœ‰æ•ˆ")

        # Show key settings
        gen = config.get('generation', {})
        scale = config.get('scale', {})
        print(f"   - æ¨¡å‹: {gen.get('model_id', 'N/A')}")
        print(f"   - è®¾å¤‡: {gen.get('device', 'N/A')}")
        print(f"   - è§„æ¨¡: {scale.get('num_persons', 'N/A')} äºº Ã— {scale.get('emotion_pairs_per_person', 'N/A')} å¯¹")

        return True
    except Exception as e:
        print(f"âŒ config.yaml è§£æé”™è¯¯: {e}")
        return False


def check_files():
    """Check if all pipeline scripts exist."""
    scripts = [
        "run_pipeline.py",
        "step1_generate_prompts.py",
        "step2_generate_images.py",
        "step3_crop_pairs.py",
        "step4_filter_pairs.py",
        "step5_package_dataset.py",
    ]

    all_exist = True
    for script in scripts:
        if Path(script).exists():
            print(f"âœ… {script}")
        else:
            print(f"âŒ {script} ä¸å­˜åœ¨")
            all_exist = False

    return all_exist


def main():
    print("="*60)
    print("FLUX Face Emotion Pipeline - ç¯å¢ƒæ£€æŸ¥")
    print("="*60)

    results = {}

    print("\nğŸ“Œ Python ç‰ˆæœ¬:")
    results['python'] = check_python_version()

    print("\nğŸ“Œ CUDA å’Œ GPU:")
    results['cuda'] = check_cuda()

    print("\nğŸ“Œ æ ¸å¿ƒä¾èµ–åŒ…:")
    core_packages = [
        ('torch', None),
        ('diffusers', None),
        ('transformers', None),
        ('accelerate', None),
    ]

    for pkg, import_name in core_packages:
        results[pkg] = check_package(pkg, import_name)

    print("\nğŸ“Œ é¢éƒ¨å’Œæƒ…æ„Ÿè¯†åˆ«:")
    face_packages = [
        ('insightface', None),
        ('onnxruntime', None),
        ('cv2', 'cv2'),
        ('hsemotion', None),
    ]

    for pkg, import_name in face_packages:
        results[pkg] = check_package(pkg, import_name)

    print("\nğŸ“Œ å›¾åƒå’Œæ•°æ®å¤„ç†:")
    data_packages = [
        ('PIL', 'PIL'),
        ('numpy', None),
        ('datasets', None),
        ('tqdm', None),
        ('jsonlines', None),
        ('yaml', 'yaml'),
    ]

    for pkg, import_name in data_packages:
        results[pkg] = check_package(pkg, import_name)

    print("\nğŸ“Œ ç¯å¢ƒå˜é‡:")
    env_results = check_env_vars()
    results.update(env_results)

    print("\nğŸ“Œ é…ç½®æ–‡ä»¶:")
    results['config'] = check_config()

    print("\nğŸ“Œ æµæ°´çº¿è„šæœ¬:")
    results['scripts'] = check_files()

    # Summary
    print("\n" + "="*60)
    print("æ£€æŸ¥æ€»ç»“:")
    print("="*60)

    critical_checks = ['python', 'cuda', 'torch', 'diffusers', 'transformers',
                      'insightface', 'hsemotion', 'config', 'scripts']
    critical_passed = all(results.get(check, False) for check in critical_checks)

    optional_checks = ['openai', 'hf']

    if critical_passed:
        print("âœ… æ‰€æœ‰å…³é”®ç»„ä»¶å·²å°±ç»ªï¼")
        print("\næ‚¨å¯ä»¥å¼€å§‹è¿è¡Œæµæ°´çº¿:")
        print("  python run_pipeline.py --backend template")
        print("\næˆ–æŸ¥çœ‹çŠ¶æ€:")
        print("  python run_pipeline.py --status")

        if not results.get('openai', False):
            print("\næ³¨æ„: å¦‚éœ€ä½¿ç”¨ GPT-4o ç”Ÿæˆ promptsï¼Œè¯·è®¾ç½® OPENAI_API_KEY:")
            print("  export OPENAI_API_KEY='your-key-here'")

        if not results.get('hf', False):
            print("\næ³¨æ„: å½“å‰ä½¿ç”¨ FLUX.2-klein-4B (æ— éœ€ HF token)")
            print("  å¦‚éœ€ä½¿ç”¨ FLUX.2-klein-9Bï¼Œè¯·è®¾ç½® HF_TOKEN")

        return 0
    else:
        print("âŒ å­˜åœ¨ç¼ºå¤±çš„å…³é”®ç»„ä»¶ï¼Œè¯·å…ˆå®‰è£…:")
        print("  pip install -r requirements.txt")

        missing = [check for check in critical_checks if not results.get(check, False)]
        print(f"\nç¼ºå¤±çš„ç»„ä»¶: {', '.join(missing)}")

        return 1


if __name__ == "__main__":
    sys.exit(main())
